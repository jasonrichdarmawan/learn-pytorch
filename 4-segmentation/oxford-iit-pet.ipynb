{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. https://medium.com/towards-data-science/efficient-image-segmentation-using-pytorch-part-1-89e8297a0923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import OxfordIIITPet\n",
    "\n",
    "pet_trainval = OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"segmentation\", download=True)\n",
    "pet_test = OxfordIIITPet(root=\"data\", split=\"test\", target_types=\"segmentation\", download=True)\n",
    "pet_trainval, pet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch import unique\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "image: Image = pet_trainval[0][0]\n",
    "mask: Image = pet_trainval[0][1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask)\n",
    "plt.title(\"Mask\")\n",
    "\n",
    "unique(pil_to_tensor(mask)) # Trimap: 1=Pet, 2=Background, 3=Border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from torch.nn import Linear\n",
    "\n",
    "model = Linear(1000, 500) # no # of parameters = 1000*500 (weights) + 500 (bias) = 500500\n",
    "summary(\n",
    "  model,\n",
    "  input_size=(1, 1000),\n",
    "  col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    "  col_width=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. https://medium.com/p/bed68cadd7c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from src import oxford_iiit_pet_augmented, to_device, utils\n",
    "reload(oxford_iiit_pet_augmented)\n",
    "reload(to_device)\n",
    "reload(utils)\n",
    "OxfordIIITPetAugmented = oxford_iiit_pet_augmented.OxfordIIITPetAugmented\n",
    "ToDevice = to_device.ToDevice\n",
    "float_to_long = utils.float_to_long\n",
    "get_device = to_device.get_device\n",
    "from torchvision.transforms import (ToTensor, Compose, Resize, InterpolationMode, \n",
    "                                    RandomHorizontalFlip, ColorJitter, Lambda)\n",
    "\n",
    "pre_transform = ToTensor()\n",
    "pre_target_transform = ToTensor()\n",
    "common_transform = Compose([\n",
    "    ToDevice(get_device()),\n",
    "    Resize((128, 128), interpolation=InterpolationMode.NEAREST),\n",
    "    RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "post_transform = Compose([\n",
    "    ColorJitter(contrast=0.3)\n",
    "])\n",
    "post_target_transform = Compose([\n",
    "    Lambda(float_to_long)\n",
    "])\n",
    "pet_trainval = OxfordIIITPetAugmented(root=\"data\", split=\"trainval\", target_types=\"segmentation\", \n",
    "                                      download=True, \n",
    "                                      pre_transform=pre_transform,\n",
    "                                      pre_target_transform=pre_target_transform,\n",
    "                                      common_transform=common_transform,\n",
    "                                      post_transform=post_transform,\n",
    "                                      post_target_transform=post_target_transform)\n",
    "pet_test = OxfordIIITPetAugmented(root=\"data\", split=\"test\", target_types=\"segmentation\",\n",
    "                                  download=True,\n",
    "                                  pre_transform=pre_transform,\n",
    "                                  pre_target_transform=pre_target_transform,\n",
    "                                  common_transform=common_transform,\n",
    "                                  post_transform=post_transform,\n",
    "                                  post_target_transform=post_target_transform)\n",
    "pet_trainval, pet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pet_trainval_loader = DataLoader(pet_trainval, batch_size=64, shuffle=True)\n",
    "pet_test_loader = DataLoader(pet_test, batch_size=21, shuffle=True)\n",
    "\n",
    "pet_trainval_images, pet_trainval_masks = next(iter(pet_trainval_loader))\n",
    "pet_test_images, pet_test_masks = next(iter(pet_test_loader))\n",
    "pet_trainval_images.shape, pet_trainval_masks.shape, pet_test_images.shape, pet_test_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "ToPILImage()(make_grid(pet_trainval_images, nrow=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input \\in {0, 1, 2} -> divide by 2.0 to normalize to [0, 1]\n",
    "ToPILImage()(make_grid(pet_trainval_masks / 2.0, nrow=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the model is working\n",
    "from importlib import reload\n",
    "from src import seg_net, to_device\n",
    "reload(seg_net)\n",
    "reload(to_device)\n",
    "ImageSegmentation = seg_net.ImageSegmentation\n",
    "get_device = to_device.get_device\n",
    "\n",
    "model = ImageSegmentation(num_classes=3, kernel_size=3)\n",
    "model.eval()\n",
    "device = get_device()\n",
    "model.to(device)\n",
    "model(pet_trainval_images.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from src import iou_metric\n",
    "reload(iou_metric)\n",
    "IoULoss = iou_metric.IoULoss\n",
    "from torch import rand, randint, long\n",
    "\n",
    "def test_custom_iou_loss():\n",
    "  #         N, C, H, W\n",
    "  x = rand((2, 3, 2, 2), requires_grad=True)\n",
    "  y = randint(0, 3, (2, 1, 2, 2), dtype=long)\n",
    "  z = IoULoss(softmax=True)(x, y)\n",
    "  return z\n",
    "\n",
    "test_custom_iou_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "from src import train_model\n",
    "reload(train_model)\n",
    "print_test_dataset_masks = train_model.print_test_dataset_masks\n",
    "\n",
    "if not os.path.exists(\"progress\"):\n",
    "  os.mkdir(\"progress\")\n",
    "\n",
    "print_test_dataset_masks(model, device, pet_test_images, pet_test_masks, epoch=0, save_path=None, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, lr_scheduler\n",
    "\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from src import train_model\n",
    "reload(train_model)\n",
    "train_loop = train_model.train_loop\n",
    "\n",
    "train_loop(model=model, device=device, trainval_loader=pet_trainval_loader, \n",
    "           test_data=(pet_test_images, pet_test_masks), epochs=(1,21),\n",
    "           optimizer=optimizer, scheduler=scheduler, save_path=\"progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "\n",
    "save(model.state_dict(), \"progress/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(param.numel() for param in model.parameters()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model parameters: {:.2f}M\".format((sum(param.numel() for param in model.parameters())) / 1e6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
