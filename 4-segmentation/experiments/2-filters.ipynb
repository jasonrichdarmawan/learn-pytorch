{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the feature count of the input (i.e. in_channels) makes the filters deeper (`w0[:,:,0]`, `w0[:, :, 1]`) and increasing the feature count of the output (i.e. out_channels) increases the number of filters (Filter `w0`, `w1`). So, doubling the number of features actually quadruples the amount of computation.\n",
    "\n",
    "![](./2-filters/2025-02-19%2016.24.21.gif)\n",
    "\n",
    "Reference:\n",
    "1. https://cs231n.github.io/convolutional-networks/#conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original conv weight shape: torch.Size([32, 16, 3, 3])\n",
      "Number of parameters in original conv: 4608\n",
      "Doubled conv weight shape: torch.Size([64, 32, 3, 3])\n",
      "Number of parameters in doubled conv: 18432\n",
      "Expected parameters (4x original): 18432\n",
      "Quadrupled computation: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define kernel size for demonstration\n",
    "kernel_size = 3\n",
    "\n",
    "# Original convolution layer:\n",
    "# in_channels = 16, out_channels = 32.\n",
    "conv_original = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=kernel_size)\n",
    "params_original = conv_original.weight.numel()\n",
    "print(\"Original conv weight shape:\", conv_original.weight.shape)\n",
    "print(\"Number of parameters in original conv:\", params_original)\n",
    "\n",
    "# Doubling both the in_channels and out_channels:\n",
    "# in_channels becomes 32, out_channels becomes 64.\n",
    "conv_doubled = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=kernel_size)\n",
    "params_doubled = conv_doubled.weight.numel()\n",
    "print(\"Doubled conv weight shape:\", conv_doubled.weight.shape)\n",
    "print(\"Number of parameters in doubled conv:\", params_doubled)\n",
    "\n",
    "# Show how the parameter count quadruples:\n",
    "expected_params_doubled = 4 * params_original\n",
    "print(\"Expected parameters (4x original):\", expected_params_doubled)\n",
    "print(\"Quadrupled computation:\", params_doubled == expected_params_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard filter shape (3 input channels, 16 filters): torch.Size([16, 3, 3, 3])\n",
      "Deeper filter shape (6 input channels, 16 filters): torch.Size([16, 6, 3, 3])\n",
      "More filters shape (3 input channels, 32 filters): torch.Size([32, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "kernel_size = 3\n",
    "\n",
    "# --- Demonstration of \"makes the filters deeper\" ---\n",
    "# Here, each filter must cover each input channel.\n",
    "# Original convolution with 3 input channels (e.g., an RGB image).\n",
    "conv_standard = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size)\n",
    "print(\"Standard filter shape (3 input channels, 16 filters):\", conv_standard.weight.shape)\n",
    "# Shape: (16, 3, 3, 3)\n",
    "\n",
    "# Increasing the number of input channels to 6. \n",
    "# Now, each filter becomes deeper to cover all 6 input channels.\n",
    "conv_deeper_filters = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=kernel_size)\n",
    "print(\"Deeper filter shape (6 input channels, 16 filters):\", conv_deeper_filters.weight.shape)\n",
    "# Shape: (16, 6, 3, 3)\n",
    "\n",
    "# --- Demonstration of \"increases the number of filters\" ---\n",
    "# Here, we increase the number of output channels.\n",
    "# With 3 input channels and 16 output channels, we have 16 filters.\n",
    "conv_more_filters = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=kernel_size)\n",
    "print(\"More filters shape (3 input channels, 32 filters):\", conv_more_filters.weight.shape)\n",
    "# Shape: (32, 3, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depthwise Separable Convolution\n",
    "\n",
    "![](./2-filters/depthwise.png)\n",
    "![](./2-filters/depthwise-separable-convolution.png)\n",
    "\n",
    "Reference:\n",
    "1. https://www.youtube.com/watch?v=vVaRhZXovbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depthwise conv weight shape: torch.Size([4, 1, 3, 3])\n",
      "Pointwise conv weight shape: torch.Size([16, 4, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "kernel_size = 3\n",
    "\n",
    "# --- Depthwise Convolution ---\n",
    "# Here, in_channels=4 with groups=4 means each channel is convolved independently.\n",
    "depthwise_conv = nn.Conv2d(in_channels=4, out_channels=4, kernel_size=kernel_size, groups=4)\n",
    "print(\"Depthwise conv weight shape:\", depthwise_conv.weight.shape)\n",
    "# Expected shape: (4, 1, 3, 3) â€“ one filter per input channel\n",
    "#                 (number of filters, filter depth, kernel height, kernel width)\n",
    "\n",
    "# --- Pointwise Convolution ---\n",
    "# A 1x1 convolution that mixes the channels, increasing the number of filters.\n",
    "# This example mixes 4 channels and produces 16 output channels.\n",
    "pointwise_conv = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=1)\n",
    "print(\"Pointwise conv weight shape:\", pointwise_conv.weight.shape)\n",
    "# Expected shape: (16, 4, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard conv weight shape: torch.Size([8, 8, 3, 3])\n",
      "Depthwise conv weight shape: torch.Size([8, 1, 3, 3])\n",
      "Pointwise conv weight shape: torch.Size([8, 8, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "kernel_size = 3\n",
    "\n",
    "# --- Standard Convolution ---\n",
    "standard_conv = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=kernel_size)\n",
    "print(\"Standard conv weight shape:\", standard_conv.weight.shape)\n",
    "\n",
    "# --- Depthwise Convolution ---\n",
    "depthwise_conv = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=kernel_size, groups=8)\n",
    "print(\"Depthwise conv weight shape:\", depthwise_conv.weight.shape)\n",
    "\n",
    "# --- Pointwise Convolution ---\n",
    "pointwise_conv = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1)\n",
    "print(\"Pointwise conv weight shape:\", pointwise_conv.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Convolution:\n",
      "Weight shape: torch.Size([8, 8, 3, 3])\n",
      "Total parameters: 576\n",
      "\n",
      "Depthwise Separable Convolution:\n",
      "Depthwise weight shape: torch.Size([8, 1, 3, 3])\n",
      "Pointwise weight shape: torch.Size([8, 8, 1, 1])\n",
      "Total parameters: 136\n",
      "\n",
      "Parameter reduction factor: 4.24\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "kernel_size = 3\n",
    "in_channels = 8\n",
    "out_channels = 8\n",
    "\n",
    "# --- Standard Convolution ---\n",
    "# This applies out_channels independent filters each spanning all in_channels.\n",
    "standard_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
    "standard_params = standard_conv.weight.numel()\n",
    "\n",
    "print(\"Standard Convolution:\")\n",
    "print(\"Weight shape:\", standard_conv.weight.shape)\n",
    "print(\"Total parameters:\", standard_params)\n",
    "# Weight shape: (8, 8, 3, 3)\n",
    "\n",
    "# --- Depthwise Separable Convolution ---\n",
    "# Step 1: Depthwise Convolution: groups = in_channels to convolve each channel independently.\n",
    "depthwise_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, groups=in_channels)\n",
    "depthwise_params = depthwise_conv.weight.numel()\n",
    "\n",
    "# Step 2: Pointwise Convolution: 1x1 convolution to mix channels.\n",
    "pointwise_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n",
    "pointwise_params = pointwise_conv.weight.numel()\n",
    "\n",
    "total_ds_params = depthwise_params + pointwise_params\n",
    "\n",
    "print(\"\\nDepthwise Separable Convolution:\")\n",
    "print(\"Depthwise weight shape:\", depthwise_conv.weight.shape)\n",
    "print(\"Pointwise weight shape:\", pointwise_conv.weight.shape)\n",
    "print(\"Total parameters:\", total_ds_params)\n",
    "\n",
    "# --- Comparison ---\n",
    "print(\"\\nParameter reduction factor: {:.2f}\".format(standard_params / total_ds_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
